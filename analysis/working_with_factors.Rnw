\documentclass[fleqn,10pt,lineno]{wlpeerj}

\usepackage{url}

\let\proglang=\textsf
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\def\newblock{\hskip .11em plus .33em minus .07em}


\title{Wrangling categorical data in R}

\author[1]{Amelia McNamara}
\author[2]{Nicholas J Horton}
\affil[1]{Statistical and Data Sciences Program, Smith College}
\affil[2]{Mathematics and Statistics Department, Amherst College}


\keywords{statistical computing; data derivation; data science; data management}

\begin{abstract}
Data wrangling is a critical foundation of data science. Wrangling of categorical data is an important component of the 
data preparation process.
%analysis cycle.  
% XX AM note change
Aspects of these operations can sometimes be tricky, particularly for complex transformations that arise in real-world settings.  This paper discusses aspects of categorical variable transformations in R. We consider several motivating examples, suggest defensive coding strategies, and outline principles for data wrangling to help ensure data quality and sound analysis.
\end{abstract}

\begin{document}

<<setup, include=FALSE>>=
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, 
                      size='footnotesize', cache=FALSE, error=TRUE, tidy=FALSE)
@

\flushbottom
\maketitle
\thispagestyle{empty}

\section*{Introduction}

Wrangling skills provide an intellectual and practical foundation for data science. Because of the complexity of some transformations, careless data derivation operations can lead to errors or inconsistencies in analysis. The wrangling of categorical data presents particular challenges and is highly relevant because so many variables are categorical (e.g., gender, income bracket, U.S. state). 

It's important that statistical and data science tools foster good practice and provide a robust environment for data wrangling and data management.  This paper focuses on how \proglang{R} deals with categorical data, and showcases best practices for categorical data manipulation in \proglang{R} to produce reproducible workflows. 

In this paper, we consider a number of common idioms related to categorical data that often arise in data cleaning and preparation, propose some guidelines for defensive coding, and discuss some settings where analysts often get tripped up when working with categorical data. For example, data ingested into \proglang{R} from spreadsheets can lead to problems with categorical data because of the different storage methods possible in both \proglang{R} and the spreadsheets themselves. The examples below will help flag when these issues arise or avoid them altogether. 

To ground our work, we will compare and contrast how categorical data are treated in \pkg{base} \proglang{R} versus the so-called tidyverse~\citep{Wic2014}. Tools from the tidyverse, discussed in another paper in this special issue (see https://github.com/dsscollection/tidyflow), are designed to make analysis purer, more predictable, and pipeable. They help facilitate a reproducible workflow where a new version of the data could be supplied in the code with updated results produced~\citep{Bro2015}. Wrangling of categorical data can make this task even more complex (e.g., if a new level of a categorical variable is added in an updated dataset or inadvertently introduced by a careless error in a spreadsheet to be ingested into \proglang{R}).


\section*{Categorical data in R- factors and strings}
Consider a variable describing gender that includes categories \verb#male#, \verb#female# and \verb#non-conforming#. In \proglang{R}, there are two ways to store this information. One is to use a series of character strings, and the other is to store it as a factor. 

Historically, storing categorical data as a factor variable was more efficient than storing the same data as strings, because factor variables only store the factor labels once~\citep{Pen2015, Lum2015}. However, \proglang{R} uses hashed versions of all character strings, so the storage issue is no longer a consideration~\citep{Pen2015}. For historical reasons, many functions store variables by default as factors.

Factors can be very tricky to deal with, since many operations applied to them return different values than when applied to character vectors.  As an example, consider a set of decades,

<<>>=
x1 <- c(10, 10, 20, 20, 40)
x1f <- factor(x1)
ds <- data.frame(x1, x1f)
library(dplyr)
ds <- ds %>%
  mutate(x1recover = as.numeric(x1f))
ds
@

Instead of creating a new variable with a numeric version of the value of the factor variable \verb#x1f# the variable is created with a factor number (i.e., 10 is mapped to 1, 20 is mapped to 2, and 40 is mapped to 3). This result is unexpected because \verb#base::as.numeric()# is intended to recover numeric information by coercing a character variable. Compare the following:

<<>>=
as.numeric(c("hello"))
as.numeric(factor(c("hello")))
@

The unfortunate behavior of factors in base \proglang{R} has led to an online movement against the default behavior of many data import functions to take any variable composed as strings and automatically convert the variable to a factor. The tidyverse is part of this movement, with functions from the \pkg{readr} package defaulting to leaving strings as-is. (Others have chosen to add \verb#options(stringAsFactors=FALSE)# into their startup commands.)

Although the storage issues have been solved, and there are problems with defaulting strings to factors, factors are still necessary for some data analytic tasks. The most salient case is in modeling. When you pass a factor variable into \verb#lm()# or \verb#glm()#, \proglang{R} automatically creates indicator (or more pejoratively `dummy') variables for each of the levels and picks one as a reference group. This behavior is lost if the variable is stored as a character vector. Factor variables also allow for the possibility of ordering between classes. Text strings \verb#low, medium, high# would not preserve the ordering inherent in the groups. Again, this can be important for modeling when doing ordinal logistic regression and multinomial logistic regression. 

While factors are important, they can often be hard to deal with. Because of the way the group numbers are stored separately from the factor labels, it can be easy to overwrite data in such a way that the original data are lost. In this paper, we will suggest best practices for working with factor data. 

To motivate this process, we will consider data from the General Social Survey~\citep{GSS2016}. The General Social Survey is a product of the National Data Program for the Social Sciences, and the survey has been conducted since 1972 by NORC at the University of Chicago. It contains data on many factors of social life, and is widely used by social scientists. (In this paper we consider data from 2014.)

There are some import issues inherent to the data which are not particular to categorical data (see Appendix A for details). 
% XX AM please note change to previous sentence
We'll work with the data that has cleaned variable names.

<<>>=
library(dplyr)
GSS <- read.csv("../data/GSScleaned.csv")
glimpse(GSS)
@

The remainder of this paper is organized around case studies (examples) related to particular tasks:
\begin{enumerate}
\item Changing the labels of factor levels,
\item Reordering factor levels,
\item Combining several levels into one (both string-like labels and numeric, probably go together), and
\item Making derived factor variables.
\end{enumerate}

Each case study begins with a problem, and then presents several solutions. Typically, a method using only \pkg{base} \proglang{R} functions is contrasted with an approach from the tidyverse with some annotations of the code as needed. We will argue that the tidyverse solution is more robust. 

\section*{Changing the labels of factor levels}
In our first example, we will be considering the labor status variable. It has \Sexpr{length(levels(GSS$Labor.force.status))} factor levels. Most of the labels are spelled out fully, but a few are strangely formatted. We want to change this. 

This is a specific case of the more general problem of changing the text of one (or more) of the factor labels, so it appears more nicely formatted in a \pkg{ggplot2} plot, for example.

There are two typical approaches in \pkg{base} \proglang{R}. One is more compact, but depends on the levels of the factor not changing in the data being fed in, and the other is more robust, but extremely verbose. In contrast, the \pkg{dplyr} package offers a method that is much more human readable, while also supporting reproducibility. 


\subsection*{Compact but fragile (base R)}
<<>>=
levels(GSS$Labor.force.status)
summary(GSS$Labor.force.status)
@

<<>>=
levels(GSS$Labor.force.status) <- c(levels(GSS$Labor.force.status)[1:5], 
                             "Temporarily not working", 
                             "Unemployed, laid off", 
                             "Working full time", 
                             "Working part time")
summary(GSS$Labor.force.status)
@

This method is less than ideal, because it depends on the data coming in with the factor levels ordered in a particular way. By default, \proglang{R} orders factor levels alphabetically. So, ``Keeping house'' is first not because it is the most common response, but simply because `k` comes first in the alphabet. If the data gets changed outside of R, for example so that responses currently label ``Working full time'' get labeled ``Full time work'', the code will silently fail with invalid results. 

The workflow will also fail if additional factor levels are added after the fact. In our experience, both with students and scientific collaborators, spreadsheet data can be easily changed in these ways~\citep{Lee2016}. 

\subsection*{Robust but verbose (base R)}
Another (more robust method) to recode this variable in \pkg{base} \proglang{R} is to use subsetting to overwrite particular values in the data. 

<<>>=
summary(GSS$Political.party.affiliation)
GSS$NewParty <- as.character(GSS$Political.party.affiliation)
GSS$NewParty[GSS$Political.party.affiliation=="Ind,near dem"] <- 
  "Independent, near democrat"
GSS$NewParty[GSS$Political.party.affiliation == "Ind,near rep"] <- 
  "Independent, near republican"
GSS$NewParty[GSS$Political.party.affiliation == "Not str democrat"] <- 
  "Not strong democrat"
GSS$NewParty <- factor(GSS$NewParty)
summary(GSS$NewParty)
@

This approach is much more robust, because if the labels or ordering of levels changes before this code is run it will not overwrite labels on the incorrect data. However, this approach has a number of limitations in addition to being tedious and error prone. It is possible to miss cases, and misspelling and cut-and-paste errors can mean that pieces of the code do not actually do anything. 


\subsection*{Direct and robust (dplyr)}

The \verb#recode()# function in the \pkg{dplyr} package is a vector function, which combines the robustness of the second base R method while also reducing the verbosity. It still suffers from the problem of misspelling and cut-and-paste errors, because it will not throw errors if you try to recode a level that does not exist. 
<<>>=
GSS <- GSS %>% 
  mutate(dplyrParty =  
    recode(Political.party.affiliation, 
           `Not str republican ` = "Not a strong republican",
           `Ind,near dem` = "Independent, near democrat",
           `Ind,near rep` = "Independent, near republican",
           `Not str democrat` = "Not a strong democrat"))
summary(GSS$dplyrParty)
@
In the above example, notice the trailing space after ``Not str republican" and how the original factor level persists after the recode. 
% XX AM not sure what's meant by that: can you elaborate or clarify?

\subsection*{Aside -- Editing whitespace out of levels}

Whitespace can be dealt with when data is read, or later using string manipulations. This can be done using the \verb#trimws()# function  in \pkg{base} \proglang{R}. 
<<>>=
gender <- factor(c("male ", "male  ", "male    ", "male"))
levels(gender)
gender <- factor(trimws(gender))
levels(gender)
@


\section*{Reordering factor levels}
Often, factor levels have a natural ordering to them. However, the default in \pkg{base} \proglang{R} is to order levels alphabetically. So, users must have a way to impose order on their factor variables. 

Again, there is a fragile way to reorder the factor levels in base R, and a more robust method in the tidyverse. 

\subsection*{Fragile method (base R)}
<<>>=
summary(GSS$Opinion.of.family.income)
levels(GSS$Opinion.of.family.income)
levels(GSS$Opinion.of.family.income) <- 
  levels(GSS$Opinion.of.family.income)[c(5,1:3,6,4,7)]
levels(GSS$Opinion.of.family.income)
@

This is both verbose and depends on the number and order of the levels staying the same. If another factor level is added to the dataset, the above code will throw an error because the number of levels differs. This example illustrates why it is sometimes dangerous to replace an old version of a data frame with a new version.

Even worse, if the code gets run more than once, the order will be broken. Particularly when working dynamically, this is all too easy to do. 
% XX AM "dynamically"?  "interactively"?

<<>>=
levels(GSS$Opinion.of.family.income) <- 
  levels(GSS$Opinion.of.family.income)[c(5,1:3,6,4,7)]
levels(GSS$Opinion.of.family.income)
@

The more times the code is run, the worse it gets. 

But it gets worse! It is tempting for new analysts to write code such as the following, which completely ruins the data set.
<<>>=
test <- GSS$Opinion.of.family.income
summary(test)
levels(test) <- c("Far above average", "Above average", "Average", "Below Average", 
  "Far below average", "Don't know", "No answer")
summary(test)
@

\subsection*{Robust method}
A new addition to the tidyverse is the package \pkg{forcats}, a package for categorical data (and, the name is an anagram of the word factors!). \pkg{forcats} includes a \verb#fct_relevel()# function that does exactly what we want. It allows us to specify the order of our factor levels (either completely or partially) and is robust to re-running code in an interactive session. 
<<>>=
# devtools::install_github("hadley/forcats")
library(forcats)
summary(GSS$Opinion.of.family.income)
GSS <- GSS %>%
  mutate(Opinion.of.family.income = 
           fct_relevel(Opinion.of.family.income, 
                       "Far above average", 
                       "Above average", 
                       "Average", 
                       "Below average", 
                       "Far below average"))
summary(GSS$Opinion.of.family.income)
@

Notice that the levels we did not mention just end up at the back end of the ordering. Running the code again does not break things. 

<<>>=
GSS <- GSS %>%
  mutate(Opinion.of.family.income = 
           fct_relevel(Opinion.of.family.income, 
                       "Far above average", 
                       "Above average", 
                       "Average", 
                       "Below average", 
                       "Far below average"))
summary(GSS$Opinion.of.family.income)
@

\section*{Combining several levels into one}

\subsection*{Combining discrete levels}
This is another common task. Maybe you want fewer coefficients in your model, or the process that generated the data makes a finer distinction between categories than your research. For whatever the reason, you want to group together levels that are currently separate. 

\subsubsection*{Fragile method (base R)}
This method overwrites the labels of factor levels with repeated labels in order to group levels together. 
<<>>=
levels(GSS$Labor.force.status) <- c("Not employed", "No answer",
                             "Other", "Not employed", 
                             "Not employed", "Not employed", 
                             "Not employed", "Employed", "Employed")
summary(GSS$Labor.force.status)
@
As before, this is fragile because it depends on the order of the factor levels not changing, and on a human accurately counting the indices of all the levels they wish to change. 

\subsubsection*{Robust method}
The \verb#recode()# does what we want. 
<<>>=
levels(GSS$Race.of.respondent)
GSS <- GSS %>% 
  mutate(Race.of.respondent = recode(Race.of.respondent, 
    `Black` = "Nonwhite", 
    `Other` = "Nonwhite"))
levels(GSS$Race.of.respondent)
@


\subsection*{Combining numeric-type levels}
Combining numeric-type levels is a problem that often arises even when \verb#stringsasfactors=FALSE#. Often variables like age or income are right-censored, so there is a final category containing the lumped remainder of people. This means the data is necessarily at least a character string if not a factor. However, it may be more natural to work with numeric expressions when recoding this data. 

In this data, age is provided as an integer for respondents 18-88, but then also includes the possible answer ``89 or older'' as well as a possible ``No answer'' and NA values. 

We might want to turn this into a factor variable with two levels: 18-65, and over 65. In this case, it would be much easier to deal with a conditional statement about the numeric values, rather than writing out each of the numbers as a character vector.  

\subsubsection*{Fragile method (base R)}
In order to break this data apart as simply as possible, we need to make it numeric. To start, we recode the label for ``89 or older" to read ``89". Already, we are doing something fragile. 
<<>>=
GSS$BaseAge <- GSS$Age.of.respondent
levels(GSS$BaseAge)
levels(GSS$BaseAge) <- c(levels(GSS$BaseAge)[1:71], "89", "No answer")
@
When we look at the levels, we can see that the first 71 levels correspond to the ages 18-88, and are in the order we would expect, so we are leaving those as-is. Then we are overwriting the data where \verb#BaseAge == "89 or older"# with simply \verb#89#. Once that is done, we can convert the factor to a character vector and then to a numeric one.

<<>>=
GSS$BaseAge <- as.numeric(as.character(GSS$BaseAge))
summary(GSS$BaseAge)
@

We're avoiding the pitfall from the introduction here by not just using \verb#as.numeric()# on the factor variables (this would convert 18 to 1, 19 to 2, etc.). And of course, we're cheating a little bit here-- if we were going to use this as a numeric variable in an analysis, we wouldn't necessarily want to turn all the ``89 or older" cases into the number ``89". But, we're just on our way to a two-category factor, so those cases would have gone to the ``65 and up" category one way or the other.

Now, we can write some conditional logic
<<>>=
splitf <- function(x){
  return(ifelse(x<65, "18-64", "65 and up"))
}
summary(GSS$BaseAge)
GSS$BaseAge <- sapply(GSS$BaseAge, splitf) 
GSS$BaseAge <- factor(GSS$BaseAge)
summary(GSS$BaseAge)
@

\subsubsection*{Robust method}
The \pkg{dplyr} method follows similar logic. However, instead of explicitly overwriting \verb#89 or older# with the number 89, we use the \pkg{readr} \verb#parse_numeric()# function to remove the numbers from the factor labels. This works for the labels that already look numeric, like \verb#"18.000000"# as well as for \verb#"89 or older"#. Then, we can include the conditional logic for splitting the variable within a mutate command. 
% XX AM note that tidyr::extract_numeric() is now readr::parse_numeric()
<<>>=
library(readr)
GSS <- GSS %>%
  mutate(dplyrAge = parse_numeric(Age.of.respondent)) %>%
  mutate(dplyrAge = if_else(dplyrAge < 65, "18-65", "65 and up"),
         dplyrAge = factor(dplyrAge))
summary(GSS$dplyrAge)
@

\section*{Creating derived categorical variable}
%XX NH might be good to have the example with the GSS data. Perhaps something about income level and age together. 
Challenges often arise when data scientists need to create derived categorical variables.  As an example, consider an indicator of moderate drinking status. The National Institutes of Alcohol Abuse and Alcoholism have published guidelines for moderate drinking \cite{rethinkdrink}. 
These guidelines state that women, or men aged 65 or older should drink no more than one drink per day on average and no more than three drinks on any single day or at a sitting.
Men under age 65 should drink no more than two drinks per day on average and no more than four drinks on any single day.
The {\tt HELPmiss} dataset from the \pkg{mosaicData} package includes baseline data from a randomized clinical trial (Health Evaluation and Linkage to Primary Care).  These subjects were recruited from a detoxification center, hence those that are alcohol-involved have extremely high rates of drinking.


\begin{tabular}{l|l}
variable&description \\ \hline 
sex&gender of subject {\tt female} or {\tt male} \\
i1&average number of drinks per day (in last 30 days) \\
i2&maximum number of drinks per day (in past 30 days) \\
age&age (in years) \\ \hline
\end{tabular}


These guidelines can be used to create a new variable called {\tt abstinent} for those that reported no drinking based on the value of their {\tt i1} variable and {\tt moderate} for those that do not exceed the NIAAA guidelines, with all other non-missing values coded as {\tt highrisk}.

<<>>=
library(dplyr)
library(mosaic)
library(readr)
@

Because missing values can become especially problematic in more complex derivations, we will make one value missing so we can ensure our data wrangling accounts for the missing value.
<<>>=
data(HELPmiss)
HELPsmall <- HELPmiss %>%
  mutate(i1 = ifelse(id==1, NA, i1)) %>%  # make one value missing
  select(sex, i1, i2, age)
head(HELPsmall, 2)
@

\subsection*{Fragile method (base R)}

<<>>=
# create empty repository for new variable
drinkstat <- character(length(HELPsmall$i1))
# create abstinent group
drinkstat[HELPsmall$i1==0] = "abstinent"
# create moderate group
drinkstat[(HELPsmall$i1>0 & HELPsmall$i1<=1 & 
   HELPsmall$i2<=3 & HELPsmall$sex=="female") |
  (HELPsmall$i1>0 & HELPsmall$i1<=2 & 
   HELPsmall$i2<=4 & HELPsmall$sex=="male")] = "moderate"
# create highrisk group
drinkstat[((HELPsmall$i1>1 | HELPsmall$i2>3) & HELPsmall$sex=="female") |
  ((HELPsmall$i1>2 | HELPsmall$i2>4) & HELPsmall$sex=="male")] = "highrisk"
# account for missing values
is.na(drinkstat) <- is.na(HELPsmall$i1) | is.na(HELPsmall$i2) | 
  is.na(HELPsmall$sex)
drinkstat <- factor(drinkstat)
tally(~ drinkstat, exclude=NULL)
@

While this approach works, it is hard to follow or to debug.  The logical conditions are all correctly coded, but the missing value was not handled by default (without the \verb#is.na()# call the missing value would default to be \verb#"highrisk"# because of their extreme value for \verb#i2#).
% XX AM please review changes to this paragraph


\subsection*{Robust method (dplyr)}
<<>>=
HELPsmall <- with(HELPsmall,  # this won't work with current dplyr
  # unless HELPsmall is made accessible to mutate() through with()
  # Hadley is aware of this issue with case_when()
  mutate(HELPsmall,        
    drink_stat = case_when(
      i1 == 0 ~ "abstinent",
      i1 <= 1 & i2 <= 3 & sex=='female' ~ "moderate",
      i1 <= 1 & i2 <= 3 & sex=='male' & age >= 65 ~ "moderate",
      i1 <= 2 & i2 <= 4 & sex=='male' ~ "moderate",
      is.na(i1) ~ "missing",  # this can't be NA
      TRUE ~ "highrisk"
)))
tally( ~ drink_stat, exclude=NULL, data = HELPsmall)
@

The same logic is used, but the conditions are much clearer and comprehensible.  Instead of one big Boolean condition for 
moderate, three separate lines can be used to match the different options.  
% XX AM please review changes to this paragraph


\section*{Defensive coding}

It is always good practice to practice defensive coding.  For the setting we are considering, this might include adding conditional testing statements into code that creates or modified factors. These testing statements can help ensure that data has not changed from one session to another, or as the result of changes to the raw data. 
% XX AM please review changes to this paragraph

As an example, we might want to check that there are exactly three levels for
the drinking status variable in the HELP dataset. If there were fewer or more than three levels, something would have gone wrong with our code. We can use the \pkg{assertthat} package to help with this. 
<<>>=
library(assertthat)
levels(drinkstat)
assert_that(length(levels(drinkstat))==3)
@

We also might want to ensure that the factor labels are exactly what we were expecting. Perhaps we want to make sure our Race variable has been collapsed into two categories, with particular levels. We can use \verb#expect_equivalent()# and \verb#expect_equal()# from the \pkg{testthat} package to make this check. 

<<error = TRUE>>=
library(testthat)
str(levels(GSS$Race.of.respondent))
str(c("White", "Nonwhite"))
str(sort(c("White", "Nonwhite")))
#expect_equivalent(levels(GSS$Race.of.respondent), 
  # c("White", "Nonwhite")) # This doesn't work, but we wish it did.
expect_equivalent(levels(GSS$Race.of.respondent), c("Nonwhite", "White")) # Does work
expect_equal(levels(GSS$Race.of.respondent), c("Nonwhite", "White")) # Does work
expect_equivalent(levels(GSS$Race.of.respondent), sort(c("Nonwhite", "White"))) # Does work
@

\section*{Conclusion}

Categorical variables arise commonly in surveys and observational data.  Aspects of data wrangling involving 
categorical variables can be problematic and error-prone.  In this paper we have outlined some example case studies
where analytic tasks can be simplified and made more robust through use of new tools available in \proglang{R}.  
We believe that further work is needed to continue to make it easier to undertake analyses that requires data wrangling
and that new tools and an increased emphasis on defensive coding may help improve the quality of data science moving 
forward.
% XX AM please review

\section*{Acknowledgements}

Thanks to Hadley Wickham, who read an early version of this paper and helped solve several issues with the \pkg{forcats} package. 




\section*{Queries for reviewers}
\begin{enumerate}
\item Is it useful to demonstrate two ways to do each thing (as long as one isn't totally stupid)
\item Do we clarify why each of the tasks are hard?
\item Do we clarify why each of the standard approaches are error-prone?
\item Should we focus more on missing values?  less?
\item Add appendices  or online resources for other examples?  Move closing exercise to be online only?
\item Add other references?
\end{enumerate}

\appendix

\section*{Appendix A: Loading the data}\label{load}
Since this is a reproducible special issue, we want to make sure our data ingest process is as reproducible as possible. We are using the General Social Survey (GSS) data, which includes many years of data (1972-2014) and many possible variables (150-800 variables, depending on the year)~\citep{GSS2016}. However, the GSS data has some idiosyncrasies. So, we are attempting good-enough practices for data ingest~\citep{WilBry2016}.

The most major issue related to reproducibility is that the data is not available through an API. For SPSS and Stata users, yearly data are available for direct download on the website. For more format possibilities, users must go through an online wizard to select variables and years for the data they wish to download~\citep{GSS2016b}. For this paper, we selected a subset of the demographic variables and the year 2014. The possible output options from the wizard are Excel (either data and metadata or metadata only), SPSS, SAS, Stata, DDI, or R script. We selected both the Excel and R formats to look at the differences. 

The R format provided by the GSS is actually a Stata file and custom R script that uses the \pkg{foreign} package to do the translation for you. Here is the result of that process.

<<>>=
source('../data/GSS.r')
glimpse(GSS)
@

Obviously, the result is less than ideal. All of the factor variables are encoded as integers, but their level labels have been lost. We have to look at a codebook to determine if \verb#SEX == 1# indicates male or female. We would rather preserve the integrated level labels. In order to do this, our best option is to use the Excel file and use the \pkg{readxl} package to load it. 


<<warning=FALSE>>=
library(readxl)
GSS <- read_excel("../data/GSS.xls")
glimpse(GSS)
@

That's a little better. Now we have preserved the character strings. But, the data is not yet usable in an analysis. One problem is that some of the variable names include spaces, so they are hard to use. Also, one variable name is repeated, perhaps because of an error in the data wizard. To fix these issues, we need to rename the variables so all variables have unique names without spaces. 

<<warning=FALSE>>=
names(GSS) <- make.names(names(GSS), unique=TRUE)
names(GSS)
@

These names are an improvement, but now some are full of periods. We'd like to rename the most extreme cases to make the names more human readable. As with all the tasks in this paper, there is a fragile way to do this in \pkg{base} \proglang{R}, but we'll use the more robust \verb#rename()# function from the \pkg{dplyr} package. \verb#rename()# 

<<>>=
library(dplyr)
GSS <- GSS %>% 
  rename(Year = Gss.year.for.this.respondent.......................,
         Occupational.prestige.score.1970 = Rs.occupational.prestige.score...1970.)
names(GSS)
@
Now that we have the data loaded and the names adjusted, we can write the data to a new file for use in the body of the paper. 
<<>>=
write_csv(GSS, path="../data/GSScleaned.csv")
@

\section*{Appendix B: Closing exercise}
We have included the following as a possible closing exercise.

Subjects in the HELP study were also categorized into categories of drug and alcohol involvement, as displayed in the following table.

<<>>=
HELPbase <- HELPfull %>%
  filter(TIME==0)
tally( ~ PRIM_SUB + SECD_SUB, data=HELPbase)
@

The following coding of substance use involvement was used in the study.

\begin{tabular}{l|l}
value&description \\ \hline
0&None \\
1&Alcohol \\
2&Cocaine \\
3&Heroin \\
4&Barbituates \\
5&Benzos \\
6&Marijuana \\
7&Methadone \\
8&Opiates \\ \hline
\end{tabular}

Create a new variable called `primsub` that combines the primary and secondary substances into a categorical variable with values corresponding to primary and secondary substances of the form: {\tt alcohol only}, {\tt cocaine only}, `heroin only`, `alcohol-cocaine`, `cocaine-alcohol`, or `other`.  Code any group with fewer than 5 entries as `alcohol-other`, `cocaine-other`, or `heroin-other`.  If `PRIM\_SUB==6` make the `primsub` variable missing.

How many subjects are there in the `alcohol-none` group?  How many subjects are there in the `alcohol-other` group?  What are the three most common groups?

SOLUTION:
<<>>=
HELPbase <- with(HELPbase, 
  mutate(HELPbase, 
    primary= recode(PRIM_SUB, 
      `1`="alcohol",
      `2`="cocaine",
      `3`="heroin",
      `4`="barbituates",
      `5`="benzos",
      `6`="marijuana",
      `7`="methadone",
      `8`="opiates"),
    second=recode(SECD_SUB,
      `0`="none",
      `1`="alcohol",
      `2`="cocaine",
      `3`="heroin",
      `4`="barbituates",
      `5`="benzos",
      `6`="marijuana",
      `7`="methadone",
      `8`="opiates"),
    title=paste0(primary, "-", second) 
))
@
<<>>=
tally(~ primary, data=HELPbase)
tally(~ second, data=HELPbase)

counts <- HELPbase %>%
  group_by(primary, second) %>%
  summarise(observed=n())

merged <- left_join(HELPbase, counts, by=c("primary", "second"))
@

<<>>=
merged <- with(merged, 
  mutate(merged,
    title = 
      case_when(
        observed < 5 & primary=="alcohol" ~ "alcohol-other",
        observed < 5 & primary=="cocaine" ~ "cocaine-other",
        observed < 5 & primary=="heroin" ~ "heroin-other",
        TRUE ~ title),
    title = ifelse(primary=="marijuana", NA, title)))
tally(~ title + observed, data=merged)
@

<<>>=
tally(~ title=="alcohol-none", data=merged)
tally(~ title=="alcohol-other", data=merged)
sort(tally(~ title, data=merged), decreasing=TRUE)[1:3]
@

\bibliography{bibliography.bib}

\end{document}
